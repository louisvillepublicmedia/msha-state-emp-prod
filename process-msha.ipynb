{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, os\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MANUAL STEPS:\n",
    "1. Visit https://enforcedata.dol.gov/views/data_catalogs.php and click MSAH data \n",
    "2. Download and unzip msha_cy_oprtr_emplymnt\n",
    "3. Download and unzip msha_mine_zip\n",
    "\n",
    "These files are updated weekly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARIABLES TO CHANGE DEPENDING ON DATE FILES DOWNLOADED AND STATES DESIRED\n",
    "col_types = {'mine_id':str}\n",
    "region_filter = ['KY', 'OH', 'WV']\n",
    "#msha_data_root = '/absolute/path/to/your/downloaded/msha/data/'\n",
    "msha_data_root = '/Users/akanik/LPM/data/msha-data/msha-state-emp-prod/data/'\n",
    "\n",
    "# OTHER VARIABLES\n",
    "today = datetime.datetime.now()\n",
    "process_date = today.strftime('%Y%m%d')\n",
    "msha_cy_oprtr_emplymnt = msha_data_root + 'msha_cy_oprtr_emplymnt_20191130-0.csv'\n",
    "msha_mine = msha_data_root + 'msha_mine_20191130-0.csv'\n",
    "\n",
    "mine_data = pd.read_csv(msha_mine, escapechar='\\\\', dtype=col_types)\n",
    "oprtr_data = pd.read_csv(msha_cy_oprtr_emplymnt, dtype=col_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_coal_mines(state_list):\n",
    "    coal = mine_data['c_m_ind'] == 'C'\n",
    "    regional = mine_data['state_abbr'].isin(state_list)\n",
    "    \n",
    "    if (len(state_list) == 1) and ('US' in state_list):\n",
    "        filtered_coal_mines = mine_data.loc[coal]\n",
    "        filtered_coal_unique = filtered_coal_mines.drop_duplicates(subset='mine_id')\n",
    "        return filtered_coal_unique['mine_id'].tolist()\n",
    "    else:\n",
    "        filtered_coal_mines = mine_data.loc[(coal) & (regional)]\n",
    "        filtered_coal_unique = filtered_coal_mines.drop_duplicates(subset='mine_id')\n",
    "        return filtered_coal_unique['mine_id'].tolist()\n",
    "            \n",
    "\n",
    "# This will filter each state in your region_filter list into a new csv file\n",
    "def filter_state_operators(state_list):\n",
    "    # create a 'filtered' directory if it doesn't already exist\n",
    "    directory = msha_data_root + 'filtered/'\n",
    "    \n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    # run each state in your region_filter list separately \n",
    "    for state in state_list:\n",
    "        print('Starting on ' + state)\n",
    "        \n",
    "        mine_operators_new_file = directory + state + '_oprtr_emplymnt_' + process_date + '.csv'\n",
    "        # create a single-item list out of our state so we can run it through get_state_coal_mines()\n",
    "        state_as_list = [state]\n",
    "        # return a list of coal mines ids that are in the state we're currently processing\n",
    "        filtered_coal_mines = get_state_coal_mines(state_as_list)\n",
    "        \n",
    "        print('- returned', len(filtered_coal_mines), state, 'mines')\n",
    "        \n",
    "        oprtr_data_filtered = oprtr_data.loc[oprtr_data['mine_id'].isin(filtered_coal_mines)]\n",
    "        oprtr_data_filtered.to_csv(mine_operators_new_file)\n",
    "                \n",
    "        \n",
    "# This will filter all of the state in your region_filter list into a single csv file   \n",
    "def filter_regional_operators(state_list):\n",
    "    # create a 'filtered' directory if it doesn't already exist\n",
    "    directory = msha_data_root + 'filtered/'\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        \n",
    "    # name our output file\n",
    "    region_str = '_'.join(state_list)\n",
    "    mine_operators_new_file = directory + region_str + '_oprtr_emplymnt_' + process_date + '.csv'\n",
    "    \n",
    "    print('Starting on region ' + region_str)\n",
    "    \n",
    "    # return a list of coal mine ids that are in one of the states in our region_filter\n",
    "    filtered_coal_mines = get_state_coal_mines(state_list)\n",
    "    \n",
    "    print('- returned', len(filtered_coal_mines), region_str, 'mines')\n",
    "    \n",
    "    oprtr_data_filtered = oprtr_data.loc[oprtr_data['mine_id'].isin(filtered_coal_mines)]\n",
    "    oprtr_data_filtered.to_csv(mine_operators_new_file)\n",
    "\n",
    "        \n",
    "def create_employment_production():\n",
    "    # create a 'by_year' directory if it doesn't already exist\n",
    "    directory = msha_data_root + 'filtered/by_year/'\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    # perform this on all the csv files we just created in our filtered directory\n",
    "    for file in os.listdir(msha_data_root + 'filtered/'):\n",
    "        if file.endswith('.csv'):\n",
    "            print('Aggregating employment and production for ' + file)\n",
    "            \n",
    "            regional_oprtr = pd.read_csv(msha_data_root + 'filtered/' + file)\n",
    "            # Pivot on the year\n",
    "            op_by_year = regional_oprtr.groupby('calendar_yr').agg({'avg_annual_empl':'sum',\n",
    "                                                                    'annual_coal_prod':'sum'})\n",
    "            op_by_year.sort_values('calendar_yr').to_csv(directory + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting on KY\n",
      "- returned 13613 KY mines\n",
      "Starting on OH\n",
      "- returned 1215 OH mines\n",
      "Starting on WV\n",
      "- returned 6917 WV mines\n",
      "Starting on region KY_OH_WV\n",
      "- returned 21745 KY_OH_WV mines\n",
      "Starting on region US\n",
      "- returned 35444 US mines\n",
      "Aggregating employment and production for KY_OH_WV_oprtr_emplymnt_20191210.csv\n",
      "Aggregating employment and production for KY_oprtr_emplymnt_20191210.csv\n",
      "Aggregating employment and production for OH_oprtr_emplymnt_20191210.csv\n",
      "Aggregating employment and production for US_oprtr_emplymnt_20191210.csv\n",
      "Aggregating employment and production for WV_oprtr_emplymnt_20191210.csv\n"
     ]
    }
   ],
   "source": [
    "filter_state_operators(region_filter)\n",
    "filter_regional_operators(region_filter)\n",
    "filter_regional_operators(['US'])\n",
    "create_employment_production()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
